{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "id": "tvZNJXwLajCK",
        "outputId": "43f479a5-de0c-48e9-d962-25a1f66793d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      User ID  Gender  Age  EstimatedSalary Purchased\n",
              "0    15668575       0   26            43000        No\n",
              "1    15603246       0   27            57000        No\n",
              "2    15598044       0   27            84000        No\n",
              "3    15727311       0   35            65000        No\n",
              "4    15570769       0   26            80000        No\n",
              "..        ...     ...  ...              ...       ...\n",
              "395  15672330       1   47            34000       Yes\n",
              "396  15807837       1   48            33000       Yes\n",
              "397  15592570       1   47            23000       Yes\n",
              "398  15635893       1   60            42000       Yes\n",
              "399  15706071       1   51            23000       Yes\n",
              "\n",
              "[400 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fde90801-4c93-41f5-bc2c-0fe818d42b80\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>User ID</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Purchased</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>15668575</td>\n",
              "      <td>0</td>\n",
              "      <td>26</td>\n",
              "      <td>43000</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>15603246</td>\n",
              "      <td>0</td>\n",
              "      <td>27</td>\n",
              "      <td>57000</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>15598044</td>\n",
              "      <td>0</td>\n",
              "      <td>27</td>\n",
              "      <td>84000</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>15727311</td>\n",
              "      <td>0</td>\n",
              "      <td>35</td>\n",
              "      <td>65000</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>15570769</td>\n",
              "      <td>0</td>\n",
              "      <td>26</td>\n",
              "      <td>80000</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>395</th>\n",
              "      <td>15672330</td>\n",
              "      <td>1</td>\n",
              "      <td>47</td>\n",
              "      <td>34000</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>396</th>\n",
              "      <td>15807837</td>\n",
              "      <td>1</td>\n",
              "      <td>48</td>\n",
              "      <td>33000</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>397</th>\n",
              "      <td>15592570</td>\n",
              "      <td>1</td>\n",
              "      <td>47</td>\n",
              "      <td>23000</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>398</th>\n",
              "      <td>15635893</td>\n",
              "      <td>1</td>\n",
              "      <td>60</td>\n",
              "      <td>42000</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>399</th>\n",
              "      <td>15706071</td>\n",
              "      <td>1</td>\n",
              "      <td>51</td>\n",
              "      <td>23000</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>400 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fde90801-4c93-41f5-bc2c-0fe818d42b80')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fde90801-4c93-41f5-bc2c-0fe818d42b80 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fde90801-4c93-41f5-bc2c-0fe818d42b80');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount = True)\n",
        "path = \"drive/My Drive/Colab Notebooks/Social_Network.csv\"\n",
        "df = pd.read_csv(path)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report, roc_curve, auc\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "eipbgJj8b0A9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.dropna(inplace = True)"
      ],
      "metadata": {
        "id": "vklwgcUmb8To"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x=df.iloc[:, 1:-1].values\n",
        "print(x[0:10])"
      ],
      "metadata": {
        "id": "B4_yxxL5b-il",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecd8cb6b-f952-4baf-c1b7-cceab194cb05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[    0    26 43000]\n",
            " [    0    27 57000]\n",
            " [    0    27 84000]\n",
            " [    0    35 65000]\n",
            " [    0    26 80000]\n",
            " [    0    26 52000]\n",
            " [    0    21 16000]\n",
            " [    0    28 44000]\n",
            " [    0    33 28000]\n",
            " [    0    26 72000]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['Purchased']= df['Purchased'].replace({'T':1, 'F':0})\n",
        "df['Purchased']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ytfc-bjcf7q_",
        "outputId": "fcfb94b9-40ef-4db0-f32d-ca030a5808a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       No\n",
              "1       No\n",
              "2       No\n",
              "3       No\n",
              "4       No\n",
              "      ... \n",
              "395    Yes\n",
              "396    Yes\n",
              "397    Yes\n",
              "398    Yes\n",
              "399    Yes\n",
              "Name: Purchased, Length: 400, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = df.iloc[:, -1].values\n",
        "print(y[0:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ExT3aXAgo4p",
        "outputId": "b62e208a-c1c6-4d3f-a147-ce1619a5bb9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['No' 'No' 'No' 'No' 'No' 'No' 'No' 'No' 'No' 'No']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, random_state=1)"
      ],
      "metadata": {
        "id": "M7eUJQg0hHgW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cx6lFIAShgcu",
        "outputId": "1079689b-1969-4e91-e2fe-5f0f3cc5bc13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[     0     30  79000]\n",
            " [     1     49  89000]\n",
            " [     1     35  53000]\n",
            " [     0     22  63000]\n",
            " [     0     46  96000]\n",
            " [     0     47 107000]\n",
            " [     0     34  72000]\n",
            " [     1     38  71000]\n",
            " [     0     48 138000]\n",
            " [     1     38  61000]\n",
            " [     0     37  57000]\n",
            " [     1     57  60000]\n",
            " [     0     44  39000]\n",
            " [     1     38  51000]\n",
            " [     1     28  79000]\n",
            " [     0     35  60000]\n",
            " [     0     54  26000]\n",
            " [     1     35  75000]\n",
            " [     1     23  63000]\n",
            " [     1     47  34000]\n",
            " [     0     29  83000]\n",
            " [     1     21  72000]\n",
            " [     1     60  34000]\n",
            " [     1     49  65000]\n",
            " [     1     35  91000]\n",
            " [     0     34  25000]\n",
            " [     0     41  72000]\n",
            " [     0     33  51000]\n",
            " [     0     48  30000]\n",
            " [     1     51  23000]\n",
            " [     0     49  36000]\n",
            " [     0     52  38000]\n",
            " [     1     46 117000]\n",
            " [     0     45 131000]\n",
            " [     1     42 149000]\n",
            " [     0     59  88000]\n",
            " [     0     59  42000]\n",
            " [     1     25  33000]\n",
            " [     0     46  74000]\n",
            " [     1     36 118000]\n",
            " [     0     27  54000]\n",
            " [     1     22  81000]\n",
            " [     0     37  80000]\n",
            " [     1     31  74000]\n",
            " [     0     38  50000]\n",
            " [     0     41  51000]\n",
            " [     0     39  79000]\n",
            " [     0     26  72000]\n",
            " [     1     30  87000]\n",
            " [     0     24  32000]\n",
            " [     1     49  88000]\n",
            " [     0     26  43000]\n",
            " [     0     35  57000]\n",
            " [     1     35  59000]\n",
            " [     1     29  43000]\n",
            " [     1     47  20000]\n",
            " [     0     29  47000]\n",
            " [     0     29  28000]\n",
            " [     1     24  58000]\n",
            " [     1     35  72000]\n",
            " [     1     26  15000]\n",
            " [     1     35  79000]\n",
            " [     1     58 144000]\n",
            " [     1     25  79000]\n",
            " [     1     37  75000]\n",
            " [     0     28  37000]\n",
            " [     1     26  81000]\n",
            " [     1     40  75000]\n",
            " [     1     29  61000]\n",
            " [     1     45  79000]\n",
            " [     1     34 112000]\n",
            " [     1     48  33000]\n",
            " [     0     45  45000]\n",
            " [     0     52  90000]\n",
            " [     1     20  74000]\n",
            " [     1     22  18000]\n",
            " [     0     49 141000]\n",
            " [     0     41  72000]\n",
            " [     0     26  17000]\n",
            " [     0     42  70000]\n",
            " [     1     36  52000]\n",
            " [     1     42  65000]\n",
            " [     1     29  80000]\n",
            " [     1     39  96000]\n",
            " [     1     18  52000]\n",
            " [     0     35  23000]\n",
            " [     1     35 108000]\n",
            " [     1     35  88000]\n",
            " [     0     60 108000]\n",
            " [     0     19  21000]\n",
            " [     0     40 142000]\n",
            " [     1     41  79000]\n",
            " [     1     39  77000]\n",
            " [     0     51 134000]\n",
            " [     1     28 123000]\n",
            " [     1     26  86000]\n",
            " [     0     20  82000]\n",
            " [     1     39 122000]\n",
            " [     0     41  71000]\n",
            " [     0     33  28000]\n",
            " [     1     37  70000]\n",
            " [     0     50  44000]\n",
            " [     1     29 148000]\n",
            " [     0     48  35000]\n",
            " [     0     59  29000]\n",
            " [     0     31  68000]\n",
            " [     0     33 113000]\n",
            " [     0     28  55000]\n",
            " [     1     37  52000]\n",
            " [     0     22  27000]\n",
            " [     0     36 126000]\n",
            " [     0     37  71000]\n",
            " [     0     46  41000]\n",
            " [     0     32 150000]\n",
            " [     1     49  28000]\n",
            " [     0     28  87000]\n",
            " [     0     32 117000]\n",
            " [     0     30  62000]\n",
            " [     0     47 113000]\n",
            " [     0     36  50000]\n",
            " [     1     20  49000]\n",
            " [     1     35  20000]\n",
            " [     0     38  80000]\n",
            " [     1     40  61000]\n",
            " [     0     33  69000]\n",
            " [     1     36  33000]\n",
            " [     1     52 150000]\n",
            " [     0     47  30000]\n",
            " [     1     47 105000]\n",
            " [     1     59 130000]\n",
            " [     0     60  46000]\n",
            " [     0     26  35000]\n",
            " [     1     33  43000]\n",
            " [     1     27  89000]\n",
            " [     0     50  20000]\n",
            " [     0     39  71000]\n",
            " [     0     41  60000]\n",
            " [     1     41  59000]\n",
            " [     1     35  58000]\n",
            " [     0     39  75000]\n",
            " [     0     35  44000]\n",
            " [     0     24  55000]\n",
            " [     0     35  77000]\n",
            " [     1     35  73000]\n",
            " [     0     35  71000]\n",
            " [     0     26  84000]\n",
            " [     1     25  90000]\n",
            " [     1     54  70000]\n",
            " [     1     31  18000]\n",
            " [     0     23  66000]\n",
            " [     0     58  23000]\n",
            " [     1     19  25000]\n",
            " [     1     33  31000]\n",
            " [     1     26  16000]\n",
            " [     1     18  82000]\n",
            " [     0     53  34000]\n",
            " [     0     38  55000]\n",
            " [     1     19  70000]\n",
            " [     1     39 106000]\n",
            " [     1     32 120000]\n",
            " [     1     45  22000]\n",
            " [     1     37  74000]\n",
            " [     1     35  39000]\n",
            " [     0     20  82000]\n",
            " [     0     54 108000]\n",
            " [     0     50  36000]\n",
            " [     0     57  26000]\n",
            " [     1     26  32000]\n",
            " [     0     35  50000]\n",
            " [     0     42  75000]\n",
            " [     0     41  63000]\n",
            " [     0     58  38000]\n",
            " [     1     38  61000]\n",
            " [     1     30 107000]\n",
            " [     0     21  68000]\n",
            " [     1     40  59000]\n",
            " [     1     31  76000]\n",
            " [     1     26  30000]\n",
            " [     1     30  17000]\n",
            " [     0     57  33000]\n",
            " [     0     43 133000]\n",
            " [     1     47  43000]\n",
            " [     1     27  58000]\n",
            " [     0     47 144000]\n",
            " [     0     24  89000]\n",
            " [     0     37  80000]\n",
            " [     1     41  45000]\n",
            " [     1     35  27000]\n",
            " [     1     27  20000]\n",
            " [     1     34 115000]\n",
            " [     1     25  80000]\n",
            " [     0     44 139000]\n",
            " [     0     27  31000]\n",
            " [     0     58 101000]\n",
            " [     0     41  72000]\n",
            " [     1     24  84000]\n",
            " [     1     35  55000]\n",
            " [     0     28  59000]\n",
            " [     0     54 104000]\n",
            " [     0     28  85000]\n",
            " [     1     36 144000]\n",
            " [     0     27  58000]\n",
            " [     1     60 102000]\n",
            " [     0     35  47000]\n",
            " [     1     35  38000]\n",
            " [     0     31  71000]\n",
            " [     0     31 118000]\n",
            " [     1     56  60000]\n",
            " [     1     25  87000]\n",
            " [     1     45  32000]\n",
            " [     0     27  84000]\n",
            " [     0     39  61000]\n",
            " [     0     27 137000]\n",
            " [     1     38  71000]\n",
            " [     0     47  49000]\n",
            " [     1     31  58000]\n",
            " [     1     24  19000]\n",
            " [     1     57  74000]\n",
            " [     0     37 137000]\n",
            " [     1     30  89000]\n",
            " [     0     23  28000]\n",
            " [     1     41  72000]\n",
            " [     1     43 129000]\n",
            " [     0     46  22000]\n",
            " [     1     42  54000]\n",
            " [     1     30  15000]\n",
            " [     1     47  25000]\n",
            " [     0     32 135000]\n",
            " [     0     55 125000]\n",
            " [     1     29  43000]\n",
            " [     1     28  59000]\n",
            " [     0     20  36000]\n",
            " [     1     49  86000]\n",
            " [     1     30  80000]\n",
            " [     0     56 104000]\n",
            " [     0     39  59000]\n",
            " [     1     40  47000]\n",
            " [     0     27  96000]\n",
            " [     1     42  73000]\n",
            " [     0     37  62000]\n",
            " [     1     32  18000]\n",
            " [     0     35  97000]\n",
            " [     1     38  59000]\n",
            " [     0     59  83000]\n",
            " [     1     46  59000]\n",
            " [     0     31  15000]\n",
            " [     0     31  89000]\n",
            " [     0     37  93000]\n",
            " [     0     38  50000]\n",
            " [     1     46  28000]\n",
            " [     0     53  82000]\n",
            " [     0     23  82000]\n",
            " [     0     31  34000]\n",
            " [     0     32  86000]\n",
            " [     0     51 146000]\n",
            " [     0     35  65000]\n",
            " [     1     55  39000]\n",
            " [     0     36  75000]\n",
            " [     1     46  88000]\n",
            " [     0     20  23000]\n",
            " [     0     42  79000]\n",
            " [     0     36  54000]\n",
            " [     1     36 125000]\n",
            " [     1     35  22000]\n",
            " [     0     33 149000]\n",
            " [     1     28  32000]\n",
            " [     0     38 113000]\n",
            " [     0     27  57000]\n",
            " [     0     53 104000]\n",
            " [     0     23  48000]\n",
            " [     0     42  90000]\n",
            " [     0     47  50000]\n",
            " [     0     28  44000]\n",
            " [     1     30  49000]\n",
            " [     0     52 114000]\n",
            " [     1     37 144000]\n",
            " [     1     36  60000]\n",
            " [     1     26  80000]\n",
            " [     0     22  55000]\n",
            " [     0     40  75000]\n",
            " [     1     39  42000]\n",
            " [     1     42  54000]\n",
            " [     1     46  79000]\n",
            " [     1     42  64000]\n",
            " [     0     35 147000]\n",
            " [     1     37  72000]\n",
            " [     0     57 122000]\n",
            " [     1     37  77000]\n",
            " [     0     26 118000]\n",
            " [     1     19  76000]\n",
            " [     1     23  20000]\n",
            " [     1     45  26000]\n",
            " [     1     32  18000]\n",
            " [     1     25  22000]\n",
            " [     1     49  28000]\n",
            " [     1     39  71000]\n",
            " [     0     34  43000]\n",
            " [     1     48  33000]\n",
            " [     1     48 141000]\n",
            " [     0     30 116000]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "knn.fit(x_train,y_train)"
      ],
      "metadata": {
        "id": "-c0Dg8j_h2RK",
        "outputId": "8411f5dc-d141-407b-9d62-b4b3cbda0c68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KNeighborsClassifier()"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# roc curve and auc\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from matplotlib import pyplot\n",
        "# generate 2 class dataset\n",
        "X, y = make_classification(n_samples=1000, n_classes=2, random_state=1)\n",
        "# split into train/test sets\n",
        "trainX, testX, trainy, testy = train_test_split(X, y, test_size=0.5, random_state=2)\n",
        "# generate a no skill prediction (majority class)\n",
        "ns_probs = [0 for _ in range(len(testy))]\n",
        "# fit a model\n",
        "model = LogisticRegression(solver='lbfgs')\n",
        "model.fit(trainX, trainy)\n",
        "# predict probabilities\n",
        "lr_probs = model.predict_proba(testX)\n",
        "# keep probabilities for the positive outcome only\n",
        "lr_probs = lr_probs[:, 1]\n",
        "# calculate scores\n",
        "ns_auc = roc_auc_score(testy, ns_probs)\n",
        "lr_auc = roc_auc_score(testy, lr_probs)\n",
        "# summarize scores\n",
        "print('No Skill: ROC AUC=%.3f' % (ns_auc))\n",
        "print('Logistic: ROC AUC=%.3f' % (lr_auc))\n",
        "# calculate roc curves\n",
        "ns_fpr, ns_tpr, _ = roc_curve(testy, ns_probs)\n",
        "lr_fpr, lr_tpr, _ = roc_curve(testy, lr_probs)\n",
        "# plot the roc curve for the model\n",
        "pyplot.plot(ns_fpr, ns_tpr, linestyle='--', label='No Skill')\n",
        "pyplot.plot(lr_fpr, lr_tpr, marker='.', label='Logistic')\n",
        "# axis labels\n",
        "pyplot.xlabel('False Positive Rate')\n",
        "pyplot.ylabel('True Positive Rate')\n",
        "# show the legend\n",
        "pyplot.legend()\n",
        "# show the plot\n",
        "pyplot.show()"
      ],
      "metadata": {
        "id": "wF0XauX_kPJB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# f. Analyse the performance of the classifier with various performance measures such as\n",
        "# confusion matrix, accuracy, recall, precision, specificity, f-score, Receiver operating\n",
        "# characteristic (ROC) curve and Area Under Curve (AUC) score. g. Perform feature scaling on independent variables and analyse the performance\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, precision_score, roc_curve, auc\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# generate some example data\n",
        "X, y = make_classification(n_samples=1000, n_features=10, n_classes=2, random_state=42)\n",
        "\n",
        "# split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# perform feature scaling on the independent variables\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# train a logistic regression classifier\n",
        "clf = LogisticRegression(random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# make predictions on the test set\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# calculate the confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# calculate the accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# calculate the recall\n",
        "recall = recall_score(y_test, y_pred)\n",
        "\n",
        "# calculate the precision\n",
        "precision = precision_score(y_test, y_pred)\n",
        "\n",
        "# calculate the specificity\n",
        "specificity = cm[0, 0] / (cm[0, 0] + cm[0, 1])\n",
        "\n",
        "f_score = 2 * (precision * recall) / (precision + recall)\n",
        "\n",
        "fpr, tpr, thresholds = roc_curve(y_test, clf.predict_proba(X_test)[:,1])\n",
        "auc_score = auc(fpr, tpr)\n",
        "\n",
        "print(\"Confusion Matrix:\\n\", cm)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Specificity:\", specificity)\n",
        "print(\"F-score:\", f_score)\n",
        "print(\"AUC score:\", auc_score)\n",
        "\n"
      ],
      "metadata": {
        "id": "jfA61LGc8gun"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# h. Change the value of K in KNN with 5,7,9,11 and tabulate the various TP, TN, accuracy, f-score and AUC score obtained. K value TP TN Accuracy f-score AUC score\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
        "\n",
        "X, y = make_classification(n_samples=1000, n_features=20, random_state=42)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "k_values = [5, 7, 9, 11]\n",
        "\n",
        "tp_list = []\n",
        "tn_list = []\n",
        "accuracy_list = []\n",
        "f_score_list = []\n",
        "auc_list = []\n",
        "\n",
        "for k in k_values:\n",
        "    knn = KNeighborsClassifier(n_neighbors=k)\n",
        "    knn.fit(X_train, y_train)\n",
        "    \n",
        "    y_pred = knn.predict(X_test)\n",
        "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "    tp_list.append(tp)\n",
        "    tn_list.append(tn)\n",
        "    accuracy_list.append(accuracy_score(y_test, y_pred))\n",
        "    f_score_list.append(f1_score(y_test, y_pred))\n",
        "    auc_list.append(roc_auc_score(y_test, y_pred))\n",
        "    \n",
        "print(\"K value\\tTP\\tTN\\tAccuracy\\tF-score\\tAUC score\")\n",
        "for i in range(len(k_values)):\n",
        "    print(f\"{k_values[i]}\\t{tp_list[i]}\\t{tn_list[i]}\\t{accuracy_list[i]:.2f}\\t{f_score_list[i]:.2f}\\t{auc_list[i]:.2f}\")\n"
      ],
      "metadata": {
        "id": "xI0rlYwn8oiX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# i. Analyse for which K value, the classification algorithm provides better performance.\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(k_values, accuracy_list, label='Accuracy')\n",
        "plt.plot(k_values, f_score_list, label='F-score')\n",
        "plt.plot(k_values, auc_list, label='AUC score')\n",
        "plt.legend()\n",
        "plt.xlabel('K value')\n",
        "plt.ylabel('Performance metric')\n",
        "plt.show()\n",
        "max_accuracy = max(accuracy_list)\n",
        "max_accuracy_k = k_values[accuracy_list.index(max_accuracy)]\n",
        "print(f\"Maximum accuracy: {max_accuracy:.2f} (K={max_accuracy_k})\")\n",
        "\n",
        "max_f_score = max(f_score_list)\n",
        "max_f_score_k = k_values[f_score_list.index(max_f_score)]\n",
        "print(f\"Maximum F-score: {max_f_score:.2f} (K={max_f_score_k})\")\n",
        "\n",
        "max_auc = max(auc_list)\n",
        "max_auc_k = k_values[auc_list.index(max_auc)]\n",
        "print(f\"Maximum AUC score: {max_auc:.2f} (K={max_auc_k})\")\n"
      ],
      "metadata": {
        "id": "rBC36USc8t-w"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}